# Running the Multi-LLM Demo

## Quick Start

### 1. Ensure Environment is Ready

```powershell
# Activate virtual environment
benv\Scripts\activate

# Verify dependencies installed
pip list | findstr /I "langchain huggingface"
```

Expected output should show:

- `langchain`
- `langchain-google-genai`
- `huggingface-hub`

### 2. Configure API Keys (Optional but Recommended)

Create/update `.env` file:

```env
GEMINI_API_KEY=your_gemini_api_key
HF_TOKEN=your_huggingface_token
```

**Note:** Demo will work in mock mode without API keys, but real AI validation won't run.

### 3. Run the Demo

```powershell
python demo.py
```

## What the Demo Does

The updated demo showcases:

### ğŸ”¬ Multi-Model AI Analysis

1. **Gemini 2.5 Flash** (via LangChain)
   - Primary interpretation engine
   - Patient-friendly explanations
   - Medical context generation

2. **GPT-OSS-120B** (HuggingFace)
   - Medical biomarker validation
   - Plausibility checking
   - First medical model perspective

3. **II-Medical-8B** (HuggingFace)
   - Cross-system consistency
   - Physiological coherence
   - Second medical model perspective

### ğŸ“Š Demo Workflow

```
[1/8] Loading modules
      âœ“ LangChain integration
      âœ“ HuggingFace InferenceClient

[2/8] Generating mock sensor data
      âœ“ PPG (heart rate)
      âœ“ Audio (breathing)
      âœ“ Accelerometer (gait)

[3/8] Extracting biomarkers
      âš ï¸  Unhealthy patient simulation
      - High blood pressure (158/98)
      - Tachycardia (105 bpm)
      - Low SpO2 (91%)

[4/8] Calculating risk scores
      âœ“ Per-system risks
      âœ“ Composite risk

[5/8] Trust envelope
      âœ“ Data quality assessment
      âœ“ Confidence penalties

[6/8] Multi-LLM interpretation
      ğŸ¤– Gemini 2.5 Flash
      ğŸ¤– GPT-OSS-120B
      ğŸ¤– II-Medical-8B
      âœ“ Synthesized interpretation

[7/8] Agentic validation
      ğŸ”¬ Agent 1: GPT-OSS-120B
      ğŸ”¬ Agent 2: II-Medical-8B
      âœ“ Consensus validation

[8/8] Report generation
      ğŸ“„ Patient report (PDF)
      ğŸ“„ Doctor report (PDF)
```

## Expected Output

### Console Output

```
======================================================================
HEALTH SCREENING PIPELINE - END-TO-END DEMO
======================================================================

[1/8] Loading modules...
   âœ“ All modules loaded successfully!
   âœ“ Using LangChain for Gemini
   âœ“ Using HuggingFace InferenceClient for medical models

[2/8] Generating mock sensor data...
   âœ“ PPG signal: 300 samples (camera-based)
   âœ“ Audio signal: 160000 samples (breathing)
   âœ“ Accelerometer: (500, 3) (gait analysis)

[3/8] Extracting biomarkers from signals...
   âš ï¸  Cardiovascular: HR=105 bpm (HIGH), HRV=22.0 ms (LOW)
   âš ï¸  CNS: Gait variability=0.25 (HIGH), Balance=0.45 (LOW)
   âš ï¸  Pulmonary: RR=26/min (HIGH), SpO2=91% (LOW)

[4/8] Calculating risk scores...
   âœ“ Cardiovascular: high (75.0%)
   âœ“ CNS: moderate (55.0%)
   âœ“ Pulmonary: high (70.0%)
   âœ“ COMPOSITE: high (66.7%)

[5/8] Calculating trust envelope...
   âœ“ Overall reliability: 0.78
   âœ“ Data quality: 0.85
   âœ“ Is reliable: True

[6/8] Generating Multi-LLM interpretation (3 models)...
   ğŸ¤– Querying: Gemini 2.5 Flash (LangChain)
   ğŸ¤– Querying: GPT-OSS-120B (HuggingFace)
   ğŸ¤– Querying: II-Medical-8B (HuggingFace)
   âœ“ Interpretation complete!
   âœ“ Summary length: 450 chars
   âœ“ Recommendations: 5
   âœ“ Latency: 3500ms
   ğŸ“‹ First recommendation: Consult with a healthcare professional for comprehensive evaluation...

[7/8] Running agent validation with medical models...
   ğŸ”¬ Agent 1: Using GPT-OSS-120B for biomarker plausibility
   ğŸ”¬ Agent 2: Using II-Medical-8B for cross-system consistency
   â³ Validating biomarkers...
   â³ Validating cross-system consistency...
   âœ“ Agent 1 (openai/gpt-oss-120b): flagged
   âœ“ Agent 2 (Intelligent-Internet/II-Medical-8B): flagged
   âœ“ Validation status: flagged
   âœ“ Agent agreement: 75%
   âœ“ Combined flags: 4
   âœ“ Requires review: True

[8/8] Generating PDF reports with Multi-LLM insights...
   âœ“ Patient report: PR-20260202-143022
     ğŸ“„ PDF: reports/PR-20260202-143022.pdf
     ğŸ“Š Includes insights from 3 AI models
   âœ“ Doctor report: DR-20260202-143022
     ğŸ“„ PDF: reports/DR-20260202-143022.pdf
     ğŸ”¬ Includes validation from medical AI models

======================================================================
DEMO COMPLETE - MULTI-LLM HEALTH SCREENING SUMMARY
======================================================================

Patient ID: DEMO-001
Timestamp: 2026-02-02T14:30:22.123456

AI Models Used:
  ğŸ¤– Gemini 2.5 Flash (via LangChain) - Interpretation
  ğŸ¤– GPT-OSS-120B (HuggingFace) - Validation & Interpretation
  ğŸ¤– II-Medical-8B (HuggingFace) - Validation & Interpretation

Systems Analyzed:
  ğŸ”´ cardiovascular: high (75.0%)
  ğŸŸ¡ cns: moderate (55.0%)
  ğŸ”´ pulmonary: high (70.0%)

Overall Risk: HIGH (66.7%)
Confidence: 85%
Reliability Score: 0.78

âš ï¸  REQUIRES HUMAN REVIEW
   Reason: Multiple high-risk indicators with critical flags detected

Multi-LLM Interpretation:
  ğŸ“ Summary: The health screening indicates elevated cardiovascular and pulmonary concerns...
  ğŸ’¡ Recommendations: 5 generated
  â±ï¸  Total latency: 3500ms

Reports generated in: ./reports/
  - Patient report (simple, AI-enhanced)
  - Doctor report (detailed, with validation)

To run the API server:
  uvicorn app.main:app --reload --port 8000

======================================================================
```

### Generated Files

```
reports/
â”œâ”€â”€ PR-20260202-143022.pdf  # Patient report with multi-LLM insights
â””â”€â”€ DR-20260202-143022.pdf  # Doctor report with validation details
```

## Mock Mode vs Real AI Mode

### Without API Keys (Mock Mode)

- âœ… Pipeline runs successfully
- âœ… Reports generated
- âš ï¸ LLM responses are simulated
- âš ï¸ Validation uses mock data

### With API Keys (Real AI Mode)

- âœ… Real Gemini 2.5 Flash responses
- âœ… Real GPT-OSS-120B validation
- âœ… Real II-Medical-8B validation
- âœ… Comprehensive multi-model insights
- âœ… Actual medical AI analysis

## Troubleshooting

### "Import error: langchain_google_genai"

```powershell
pip install langchain-google-genai
```

### "Import error: huggingface_hub"

```powershell
pip install huggingface-hub
```

### "No module named 'reportlab'"

```powershell
pip install reportlab
```

Reports will be skipped, but demo still runs.

### API Rate Limits

If you see rate limit errors, the demo will gracefully fall back to mock mode for that component.

## Next Steps

After running the demo:

1. **View Generated Reports**

   ```powershell
   # Open reports folder
   explorer reports
   ```

2. **Test Individual Components**

   ```powershell
   python test_llm_langchain.py
   ```

3. **Start API Server**

   ```powershell
   uvicorn app.main:app --reload --port 8000
   ```

4. **Experiment with Healthy Patient**
   Edit demo.py and change biomarker values to normal ranges to see different risk levels.

## Demo Features Highlighted

âœ… **Multi-LLM Integration** - 3 AI models working together  
âœ… **LangChain Framework** - Modern LLM orchestration  
âœ… **Medical Model Validation** - Specialized AI for healthcare  
âœ… **Agentic Consensus** - Multiple AI perspectives  
âœ… **Comprehensive Reports** - PDF generation with AI insights  
âœ… **Trust Envelope** - Data quality and confidence tracking  
âœ… **Mock Fallback** - Works without API keys for testing

Happy testing! ğŸš€ğŸ¥
